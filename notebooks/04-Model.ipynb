{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Dimensionality Reduction\n",
    "\n",
    "\n",
    "# Modeling Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model Performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "PATH_ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data.obtain import get_raw_data\n",
    "from src.data.scrub import scrub_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving cleaned data from backup.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/04-processed/titanic.csv'):\n",
    "    print(\"Importing and scrubbing raw data.\")\n",
    "    df_raw = get_raw_data()\n",
    "    df = scrub_raw_data(df_raw)\n",
    "else:\n",
    "    print(\"Retrieving cleaned data from backup.\")\n",
    "    df = pd.read_csv('data/04-processed/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy().drop(['survived'], axis=1)\n",
    "y = df['survived'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X.fillna(0))\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_0 = LogisticRegression()\n",
    "lr_0.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78244274809160308"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pr = lr_0.predict(X_te)\n",
    "accuracy_score(y_te, y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n",
      "0.77\n",
      "0.76\n",
      "0.77\n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \"\"\"\n",
    "    Loop to prove the need for cross-validated output\n",
    "    \"\"\"    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, train_size=0.8, test_size=0.2)\n",
    "    lr_0 = LogisticRegression()\n",
    "    lr_0.fit(X_tr, y_tr)\n",
    "    print accuracy_score(lr_0.predict(X_te), y_te).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.train import run_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_lr = \\\n",
    "    Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "grid_lr = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'model__penalty':['l1', 'l2'],\n",
    "    'model__class_weight':[None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_0</th>\n",
       "      <th>split_1</th>\n",
       "      <th>split_2</th>\n",
       "      <th>split_3</th>\n",
       "      <th>split_4</th>\n",
       "      <th>split_5</th>\n",
       "      <th>split_6</th>\n",
       "      <th>split_7</th>\n",
       "      <th>split_8</th>\n",
       "      <th>split_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_score__accuracy</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__f1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__precision</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__recall</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__roc_auc</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       split_0  split_1  split_2  split_3  split_4  split_5  \\\n",
       "test_score__accuracy      0.80     0.78     0.78     0.77     0.76     0.76   \n",
       "test_score__f1            0.74     0.70     0.72     0.74     0.68     0.70   \n",
       "test_score__precision     0.75     0.68     0.68     0.68     0.72     0.67   \n",
       "test_score__recall        0.73     0.73     0.78     0.80     0.65     0.73   \n",
       "test_score__roc_auc       0.79     0.77     0.78     0.78     0.74     0.76   \n",
       "train_score               0.84     0.84     0.85     0.84     0.85     0.84   \n",
       "\n",
       "                       split_6  split_7  split_8  split_9  \n",
       "test_score__accuracy      0.78     0.77     0.79     0.80  \n",
       "test_score__f1            0.70     0.68     0.68     0.75  \n",
       "test_score__precision     0.71     0.70     0.76     0.72  \n",
       "test_score__recall        0.69     0.66     0.62     0.79  \n",
       "test_score__roc_auc       0.76     0.75     0.75     0.79  \n",
       "train_score               0.84     0.85     0.84     0.84  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN GRID SEARCHES OVER 10 RANDOM SPLITS\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "list_models = \\\n",
    "map(lambda i:\n",
    "    run_classifier(\n",
    "        X=X, \n",
    "        y=y,\n",
    "        UNCORR=X.columns.tolist(),\n",
    "        TRAIN_SIZE=0.75,\n",
    "        CLF=pipe_lr, \n",
    "        GRID=grid_lr, \n",
    "        SCORING='roc_auc'),\n",
    "    range(10))\n",
    "\n",
    "df_ten_models = \\\n",
    "(pd.concat(\n",
    "    map(lambda model:\n",
    "        Series({k:model[k] for k in model.keys() if 'score' in k}), list_models),\n",
    "    axis=1))\n",
    "\n",
    "df_ten_models.columns = map(lambda i: 'split_{}'.format(i), df_ten_models)\n",
    "\n",
    "\n",
    "# PERFORMANCE ANALYSIS\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "(df_ten_models\n",
    " .T\n",
    " .drop(['train_score', 'test_score__accuracy'], axis=1)\n",
    " .plot.box(vert=False, title=\"Model Performance over ten random splits\", xlim=(0, 1))\n",
    ");\n",
    "\n",
    "df_ten_models.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick a split number from the table above.\n",
      "Valid entries (0-9)\n",
      "9\n",
      "GridSearch Results...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{u'model__C': 10, u'model__class_weight': u'balanced', u'model__penalty': u'l1'}</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__C': 10, u'model__class_weight': u'balanced', u'model__penalty': u'l2'}</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__C': 1, u'model__class_weight': u'balanced', u'model__penalty': u'l2'}</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__C': 1, u'model__class_weight': u'balanced', u'model__penalty': u'l1'}</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__C': 1, u'model__class_weight': None, u'model__penalty': u'l2'}</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_train_score  \\\n",
       "params                                                                 \n",
       "{u'model__C': 10, u'model__class_weight': u'bal...              0.85   \n",
       "{u'model__C': 10, u'model__class_weight': u'bal...              0.85   \n",
       "{u'model__C': 1, u'model__class_weight': u'bala...              0.85   \n",
       "{u'model__C': 1, u'model__class_weight': u'bala...              0.85   \n",
       "{u'model__C': 1, u'model__class_weight': None, ...              0.85   \n",
       "\n",
       "                                                    mean_test_score  \\\n",
       "params                                                                \n",
       "{u'model__C': 10, u'model__class_weight': u'bal...             0.84   \n",
       "{u'model__C': 10, u'model__class_weight': u'bal...             0.84   \n",
       "{u'model__C': 1, u'model__class_weight': u'bala...             0.84   \n",
       "{u'model__C': 1, u'model__class_weight': u'bala...             0.84   \n",
       "{u'model__C': 1, u'model__class_weight': None, ...             0.84   \n",
       "\n",
       "                                                    mean_fit_time  \n",
       "params                                                             \n",
       "{u'model__C': 10, u'model__class_weight': u'bal...           0.02  \n",
       "{u'model__C': 10, u'model__class_weight': u'bal...           0.00  \n",
       "{u'model__C': 1, u'model__class_weight': u'bala...           0.00  \n",
       "{u'model__C': 1, u'model__class_weight': u'bala...           0.00  \n",
       "{u'model__C': 1, u'model__class_weight': None, ...           0.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice = int(raw_input(\"Pick a split number from the table above.\\nValid entries (0-9)\\n\"))\n",
    "SELECTED_MODEL = list_models[choice]\n",
    "gscv = SELECTED_MODEL.get('model')\n",
    "\n",
    "print \"GridSearch Results...\\n\"\n",
    "(DataFrame(gscv.cv_results_)\n",
    " .set_index('params')\n",
    " .loc[:, ['mean_train_score', 'mean_test_score', 'mean_fit_time']]\n",
    " .sort_values('mean_test_score', ascending=False)\n",
    " .round(2)\n",
    " .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELECTED_MODEL.get('model').best_estimator_.named_steps.get('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.565, -0.405, -0.048, -0.005, -0.291, -0.46 ,  1.152, -0.101,\n",
       "       -0.129, -0.414,  0.234,  0.   , -0.283])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELECTED_MODEL.get('model').best_estimator_.named_steps.get('model').coef_[0].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_dt = \\\n",
    "Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('select', SelectKBest(score_func=f_classif)),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "grid_dt = {\n",
    "    'select__k': [5, 9, 'all'],\n",
    "    'model__max_depth':[3, 5, 7],\n",
    "    'model__min_samples_split': [20, 40, 80],\n",
    "    'model__class_weight': ['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_0</th>\n",
       "      <th>split_1</th>\n",
       "      <th>split_2</th>\n",
       "      <th>split_3</th>\n",
       "      <th>split_4</th>\n",
       "      <th>split_5</th>\n",
       "      <th>split_6</th>\n",
       "      <th>split_7</th>\n",
       "      <th>split_8</th>\n",
       "      <th>split_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_score__accuracy</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__f1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__precision</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__recall</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score__roc_auc</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       split_0  split_1  split_2  split_3  split_4  split_5  \\\n",
       "test_score__accuracy      0.79     0.81     0.76     0.77     0.81     0.76   \n",
       "test_score__f1            0.74     0.73     0.64     0.67     0.76     0.67   \n",
       "test_score__precision     0.73     0.73     0.70     0.71     0.79     0.78   \n",
       "test_score__recall        0.74     0.72     0.59     0.64     0.73     0.59   \n",
       "test_score__roc_auc       0.78     0.79     0.72     0.74     0.80     0.74   \n",
       "train_score               0.85     0.84     0.85     0.84     0.83     0.84   \n",
       "\n",
       "                       split_6  split_7  split_8  split_9  \n",
       "test_score__accuracy      0.83     0.78     0.78     0.75  \n",
       "test_score__f1            0.76     0.69     0.71     0.67  \n",
       "test_score__precision     0.80     0.68     0.76     0.67  \n",
       "test_score__recall        0.72     0.70     0.67     0.67  \n",
       "test_score__roc_auc       0.81     0.76     0.76     0.74  \n",
       "train_score               0.83     0.85     0.84     0.85  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# RUN GRID SEARCHES OVER 10 RANDOM SPLITS\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "list_models = \\\n",
    "map(lambda i:\n",
    "    run_classifier(\n",
    "        X=X, \n",
    "        y=y,\n",
    "        UNCORR=X.columns.tolist(),\n",
    "        TRAIN_SIZE=0.8,\n",
    "        CLF=pipe_dt, \n",
    "        GRID=grid_dt, \n",
    "        SCORING='roc_auc'),\n",
    "    range(10))\n",
    "\n",
    "df_ten_models = \\\n",
    "(pd.concat(\n",
    "    map(lambda model:\n",
    "        Series({k:model[k] for k in model.keys() if 'score' in k}), list_models),\n",
    "    axis=1))\n",
    "\n",
    "df_ten_models.columns = map(lambda i: 'split_{}'.format(i), df_ten_models)\n",
    "df_ten_models.round(2)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# PERFORMANCE ANALYSIS\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "(df_ten_models\n",
    " .T\n",
    " .drop(['train_score', 'test_score__accuracy'], axis=1)\n",
    " .plot.box(vert=False, title=\"Model Performance over ten random splits\", xlim=(0, 1))\n",
    ");\n",
    "\n",
    "df_ten_models.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick a split number from the table above.\n",
      "Valid entries (0-9)\n",
      "4\n",
      "GridSearch Results...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{u'model__class_weight': None, u'model__min_samples_split': 80, u'model__max_depth': 7, u'select__k': u'all'}</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__class_weight': u'balanced', u'model__min_samples_split': 80, u'model__max_depth': 7, u'select__k': u'all'}</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__class_weight': None, u'model__min_samples_split': 80, u'model__max_depth': 5, u'select__k': u'all'}</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__class_weight': u'balanced', u'model__min_samples_split': 20, u'model__max_depth': 3, u'select__k': u'all'}</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{u'model__class_weight': u'balanced', u'model__min_samples_split': 40, u'model__max_depth': 3, u'select__k': u'all'}</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_train_score  \\\n",
       "params                                                                 \n",
       "{u'model__class_weight': None, u'model__min_sam...              0.87   \n",
       "{u'model__class_weight': u'balanced', u'model__...              0.87   \n",
       "{u'model__class_weight': None, u'model__min_sam...              0.86   \n",
       "{u'model__class_weight': u'balanced', u'model__...              0.84   \n",
       "{u'model__class_weight': u'balanced', u'model__...              0.84   \n",
       "\n",
       "                                                    mean_test_score  \\\n",
       "params                                                                \n",
       "{u'model__class_weight': None, u'model__min_sam...             0.83   \n",
       "{u'model__class_weight': u'balanced', u'model__...             0.83   \n",
       "{u'model__class_weight': None, u'model__min_sam...             0.83   \n",
       "{u'model__class_weight': u'balanced', u'model__...             0.83   \n",
       "{u'model__class_weight': u'balanced', u'model__...             0.83   \n",
       "\n",
       "                                                    mean_fit_time  \n",
       "params                                                             \n",
       "{u'model__class_weight': None, u'model__min_sam...            0.0  \n",
       "{u'model__class_weight': u'balanced', u'model__...            0.0  \n",
       "{u'model__class_weight': None, u'model__min_sam...            0.0  \n",
       "{u'model__class_weight': u'balanced', u'model__...            0.0  \n",
       "{u'model__class_weight': u'balanced', u'model__...            0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# FINAL MODEL\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "choice = int(raw_input(\"Pick a split number from the table above.\\nValid entries (0-9)\\n\"))\n",
    "SELECTED_MODEL = list_models[choice]\n",
    "gscv = SELECTED_MODEL.get('model')\n",
    "\n",
    "print \"GridSearch Results...\\n\"\n",
    "(DataFrame(gscv.cv_results_)\n",
    " .set_index('params')\n",
    " .loc[:, ['mean_train_score', 'mean_test_score', 'mean_fit_time']]\n",
    " .sort_values('mean_test_score', ascending=False)\n",
    " .round(2)\n",
    " .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=80,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELECTED_MODEL.get('model').best_estimator_.named_steps.get('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                  0.56\n",
       "pclass_3                0.16\n",
       "age                     0.13\n",
       "fare                    0.08\n",
       "cabinnumber__is_null    0.05\n",
       "embarked_C              0.02\n",
       "pclass_2                0.00\n",
       "pclass_1                0.00\n",
       "embarked_S              0.00\n",
       "embarked_Q              0.00\n",
       "age__is_null            0.00\n",
       "parch                   0.00\n",
       "sibsp                   0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(SELECTED_MODEL.get('model').best_estimator_.named_steps.get('model').feature_importances_,\n",
    "       index=X.columns.tolist()).round(2).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
